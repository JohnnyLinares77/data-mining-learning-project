# R/mod_m4_server.R
# Server del M√≥dulo 4 ‚Äì √Årboles de Clasificaci√≥n

mod_m4_server <- function(input, output, session, datos_reactivos, id_sim, execution_mode = reactive("sequential")) {

  ns <- session$ns

  # --- Wrapper para silenciar toasts en M4 ---
  quiet_notify <- function(...) {
    # No-op por defecto; si quieres reactivar toasts de depuraci√≥n:
    # options(m4_debug_toasts = TRUE)
    if (isTRUE(getOption("m4_debug_toasts", FALSE))) {
      do.call(shiny::showNotification, list(...))
    } else {
      invisible(NULL)
    }
  }

  # -------------------------
  # Estado reactivo del m√≥dulo
  # -------------------------
  rv <- reactiveValues(
    # Dataset hist√≥rico (train/test)
    df_historico = NULL,
    train_data = NULL,
    test_data = NULL,

    # Modelos
    tree_model = NULL,
    pruned_model = NULL,
    poda_info = NULL,

    # Resultados
    metrics = NULL,
    test_predictions = NULL,
    n3_predictions = NULL,

    # UI state
    modelo_entrenado = FALSE,
    poda_aplicada = FALSE,
    nodo_aleatorio = NULL,
    ejercicio_actual = NULL
  )
  # -------------------------
  # UI: bloque de variables (demo vs manual)
  # -------------------------
  output$vars_block <- renderUI({
    pool_default <- c("edad","estado_civil","ubicacion","nivel_educativo",
                      "tipo_ocupacion","rubro_laboral","n_dependientes",
                      "antiguedad_cliente","n_moras_previas","dias_atraso_max",
                      "productos_activos","frecuencia_uso","cancelaciones_anticip",
                      "rfm","ingreso_declarado","ingreso_verificado","capacidad_endeud",
                      "endeudamiento_total","score_buro","tendencia_ingresos")
    pool <- tryCatch({
      df <- prepare_historic_data()
      setdiff(names(df), c("id_cliente","alerta_riesgo"))
    }, error = function(e) pool_default)

    # Siempre usar modelo preconfigurado
    if (is.null(rv$vars_demo_selected)) {
      if (!is.null(rv$semilla)) {
        set.seed(rv$semilla)
      } else set.seed(123)
      k <- min(18, max(12, length(pool)))
      rv$vars_demo_selected <- sample(pool, size = min(k, length(pool)))
    }
    tags$div(
      class = "well",
      tags$p(tags$strong("üì¶ Modelo preconfigurado por el equipo de Modelizaci√≥n.")),
      tags$p("Lee la pesta√±a ", tags$em("Introducci√≥n"),
             " y luego pulsa ", tags$strong("Entrenar Modelo"),
             " para interpretarlo y podarlo."),
      tags$p("Variables incluidas:"),
      tags$p(lapply(rv$vars_demo_selected, function(v) {
        tags$span(class = "label label-info", style = "display:inline-block;margin:2px;", v)
      })),
      tags$br(),
      tags$fieldset(disabled = "disabled",
        checkboxGroupInput(ns("vars_predictoras"), label = NULL, choices = pool,
                          selected = rv$vars_demo_selected)
      ),
      tags$small("Bloque deshabilitado - modelo preconfigurado.")
    )
  })

  # -------------------------
  # Helper: Obtener datos base
  # -------------------------
  .get_base_df_m4 <- function(d) {
    if (is.data.frame(d)) return(d)
    if (!is.null(d$base)) return(d$base)
    keys <- c("demograficas","financieras","comp_historico","clientes","post_desembolso")
    tabs <- tryCatch(Filter(Negate(is.null), d[keys]), error = function(e) list())
    if (length(tabs) == 0) stop("No se encontraron tablas base en datos_reactivos().")
    Reduce(function(a,b) merge(a,b, by = "id_cliente", all = TRUE), tabs)
  }

  # -------------------------
  # Preparar dataset hist√≥rico (interno) - USANDO GENERADOR M4 PROPIO
  # -------------------------
  prepare_historic_data <- reactive({
    message("[M4_PREPARE] Iniciando preparaci√≥n de datos hist√≥ricos con generador M4")

    # Siempre usar generador M4 propio (independiente de otros m√≥dulos)
    # Generaci√≥n de datos con manejo silencioso de errores (no mostrar toast)
    datos_hist <- tryCatch({
      gen_datos_m4(
        n = 2000,
        seed = if (!is.null(rv$semilla)) rv$semilla else 101112)
    }, error = function(e) {
      message("[M4] Error generando datos hist√≥ricos: ", conditionMessage(e))
      NULL
    })
    validate(need(!is.null(datos_hist),
                  "No se pudo preparar el hist√≥rico de M4. Revisa la preparaci√≥n de datos o vuelve a intentarlo."))

    df <- datos_hist
    message(sprintf("[M4_PREPARE] %d observaciones generadas con gen_datos_m4", nrow(df)))

    # Validaciones b√°sicas (gen_datos_m4 ya produce datos limpios)
    if (nrow(df) < 100) {
      message(sprintf("[M4_PREPARE] ERROR: Datos insuficientes (%d < 100)", nrow(df)))
      quiet_notify("Datos insuficientes para M4. Se necesitan al menos 100 observaciones.", type = "error")
      return(NULL)
    }

    # Verificar distribuci√≥n de clases
    unique_classes <- length(unique(df$alerta_riesgo))
    class_dist <- table(df$alerta_riesgo)
    message(sprintf("[M4_PREPARE] Variable dependiente: %d clases √∫nicas - %s",
                   unique_classes, paste(names(class_dist), class_dist, sep = "=", collapse = ", ")))

    if (unique_classes < 3) {
      message("[M4_PREPARE] ERROR: Se necesitan las 3 clases de riesgo")
      quiet_notify("Error en generaci√≥n de clases de riesgo.", type = "error")
      return(NULL)
    }

    rv$df_historico <- df
    message("[M4_PREPARE] Preparaci√≥n completada exitosamente")
    df
  })

  # -------------------------
  # Entrenar modelo (Paso 1) - MEJORADO CON LOGS Y VALIDACIONES PREVENTIVAS
  # -------------------------
  observeEvent(input$entrenar_modelo, {
    message("[M4_TRAIN] Iniciando entrenamiento de modelo")

    # Mostrar progreso
    progress <- shiny::Progress$new()
    progress$set(message = "Entrenando modelo...", value = 0.1)
    on.exit(progress$close())

    # Preparar datos hist√≥ricos con las variables seleccionadas
    progress$set(value = 0.2, detail = "Preparando datos...")
    df_hist <- prepare_historic_data()

    # VALIDACI√ìN: Verificar que prepare_historic_data retorn√≥ datos v√°lidos
    if (is.null(df_hist) || nrow(df_hist) < 100) {
      message("[M4_TRAIN] ERROR: Datos hist√≥ricos inv√°lidos o insuficientes")
      quiet_notify("‚ùå Error en preparaci√≥n de datos hist√≥ricos. Verifica la configuraci√≥n.", type = "error")
      return(NULL)
    }

    message(sprintf("[M4_TRAIN] Datos preparados: %d observaciones, %d variables", nrow(df_hist), ncol(df_hist)))

    # Siempre usar modelo preconfigurado
    selected_vars <- rv$vars_demo_selected
    # Excluir puntaje_riesgo para evitar fuga de informaci√≥n
    selected_vars <- setdiff(selected_vars, c("puntaje_riesgo"))

    message(sprintf("[M4_TRAIN] Variables seleccionadas disponibles: %d (%s)",
                    length(selected_vars), paste(selected_vars, collapse = ", ")))

    # Validar variables seleccionadas
    val <- validar_variables(selected_vars)
    if(!val$ok){
      message(sprintf("[M4_TRAIN] ERROR en validaci√≥n de variables: %s", val$msg))
      quiet_notify(val$msg, type = "error")
      return(invisible(NULL))
    }

    # VALIDACI√ìN: Asegurar que tenemos la variable dependiente
    if (!input$var_dependiente %in% names(df_hist)) {
      message(sprintf("[M4_TRAIN] ERROR: Variable dependiente '%s' no encontrada", input$var_dependiente))
      quiet_notify(sprintf("Variable dependiente '%s' no encontrada en los datos.", input$var_dependiente), type = "error")
      return(NULL)
    }

    # Crear dataset solo con variables seleccionadas + target
    vars_para_modelo <- c("id_cliente", selected_vars, input$var_dependiente)
    df_modelo <- df_hist[, vars_para_modelo, drop = FALSE]

    message(sprintf("[M4_TRAIN] Dataset modelo: %d filas, %d columnas", nrow(df_modelo), ncol(df_modelo)))

    # VALIDACI√ìN: Verificar que no hay NAs en el dataset final
    na_count <- sum(is.na(df_modelo))
    if (na_count > 0) {
      message(sprintf("[M4_TRAIN] WARNING: %d valores NA encontrados, removiendo filas", na_count))
      quiet_notify("Hay valores faltantes en el dataset. Limpiando datos...", type = "warning")
      df_modelo <- na.omit(df_modelo)
      if (nrow(df_modelo) < 100) {
        message(sprintf("[M4_TRAIN] ERROR: Despu√©s de remover NA quedan %d filas (< 100)", nrow(df_modelo)))
        quiet_notify("Despu√©s de remover NAs, quedan muy pocos datos.", type = "error")
        return(NULL)
      }
    }

    # Dividir en train (80%) y test (20%)
    if (!is.null(rv$semilla)) {
      set.seed(rv$semilla)
    } else set.seed(123)
    train_idx <- sample(1:nrow(df_modelo), size = 0.8 * nrow(df_modelo))
    rv$train_data <- df_modelo[train_idx, ]
    rv$test_data <- df_modelo[-train_idx, ]

    # Congelar factores al partir train/test
    factores <- c("tipo_ocupacion","ubicacion","estado_civil","nivel_educativo",
                  "rubro_laboral","frecuencia_uso","cancelaciones_anticip",
                  "tendencia_ingresos","n_dependientes","n_moras_previas","productos_activos")

    for (nm in intersect(factores, names(rv$train_data))) {
      lv <- sort(unique(rv$train_data[[nm]]))
      rv$train_data[[nm]] <- factor(rv$train_data[[nm]], levels = lv)
      rv$test_data[[nm]]  <- factor(rv$test_data[[nm]],  levels = lv)
    }

    message(sprintf("[M4_TRAIN] Divisi√≥n train/test: %d train, %d test",
                    nrow(rv$train_data), nrow(rv$test_data)))

    # VALIDACI√ìN: Verificar que tenemos datos en train y test
    if (nrow(rv$train_data) == 0 || nrow(rv$test_data) == 0) {
      message("[M4_TRAIN] ERROR: Divisi√≥n train/test fallida")
      quiet_notify("Error al dividir datos en train/test.", type = "error")
      return(NULL)
    }

    # Entrenar √°rbol grande (sobreajuste did√°ctico)
    progress$set(value = 0.5, detail = "Entrenando modelo...")
    tryCatch({
      rv$tree_model <- train_tree(
        rv$train_data, selected_vars, input$var_dependiente,
        minsplit = 5, maxdepth = 10, cp_pre = 0.001
      )
      if (is.null(rv$tree_model)) {
        message("[M4_TRAIN] ERROR: train_tree retorn√≥ NULL")
        quiet_notify("‚ùå Error al entrenar el modelo de √°rbol.", type = "error")
        return(NULL)
      }

      # VALIDACI√ìN: Verificar que el modelo se entren√≥ correctamente
      if (is.null(rv$tree_model$frame) || nrow(rv$tree_model$frame) == 0) {
        message("[M4_TRAIN] ERROR: Modelo sin estructura v√°lida")
        quiet_notify("‚ùå El modelo entrenado no tiene estructura v√°lida.", type = "error")
        return(NULL)
      }

      # Verificar que hay al menos algunos nodos terminales
      n_terminal <- sum(rv$tree_model$frame$var == "<leaf>")
      message(sprintf("[M4_TRAIN] Modelo entrenado: %d nodos terminales", n_terminal))
      if (n_terminal == 0) {
        message("[M4_TRAIN] ERROR: Modelo sin nodos terminales")
        quiet_notify("‚ùå El modelo no gener√≥ nodos terminales.", type = "error")
        return(NULL)
      }

    }, error = function(e) {
      message(sprintf("[M4_TRAIN] ERROR en train_tree: %s", e$message))
      quiet_notify(sprintf("‚ùå Error en train_tree: %s", substr(e$message, 1, 100)), type = "error")
      return(NULL)
    })

    progress$set(value = 0.9, detail = "Finalizando...")

    rv$modelo_entrenado <- TRUE
    message("[M4_TRAIN] Entrenamiento completado exitosamente")

    output$mensaje_entrenamiento <- renderUI({
      used <- tryCatch(unique(rv$tree_model$frame$var[rv$tree_model$frame$var != "<leaf>"]),
                       error = function(e) character(0))
      div(class = "alert alert-success",
          paste0(
            if (isTRUE(input$demo_auto)) "[Demo] " else "",
            "Modelo entrenado: ", nrow(rv$train_data), " train / ", nrow(rv$test_data), " test. ",
            "Variables del modelo: ", paste(selected_vars, collapse = ", "), ". ",
            "Variables efectivas en el √°rbol: ",
            if (length(used)) paste(used, collapse = ", ") else "(ninguna)")
      )
    })

    progress$set(value = 1.0, detail = "Completado")
    quiet_notify("‚úÖ Modelo entrenado exitosamente. Procede a interpretar los nodos.", type = "message")
    updateTabsetPanel(session, "tabs", selected = "Interpretaci√≥n de Nodos")
  })

  # -------------------------
  # Tab 2: Interpretaci√≥n de Nodos
  # -------------------------

  # Visualizaci√≥n del √°rbol
  output$plot_arbol <- renderPlot({
    req(rv$tree_model)

    # VALIDACI√ìN: Verificar que el modelo tiene la estructura esperada
    if (is.null(rv$tree_model$frame) || nrow(rv$tree_model$frame) == 0) {
      plot.new()
      text(0.5, 0.5, "Modelo de √°rbol no v√°lido o vac√≠o", cex = 1.2)
      return()
    }

    tryCatch({
      # Mostrar siempre el √°rbol original en esta pesta√±a, incluso si ya se aplic√≥ poda.
      rpart.plot::rpart.plot(rv$tree_model, main = "√Årbol de Clasificaci√≥n Original",
                            extra = 104, box.palette = "RdYlGn", shadow.col = "gray", roundint = FALSE)
    }, error = function(e) {
      plot.new()
      text(0.5, 0.5, paste("Error al graficar √°rbol:\n", substr(e$message, 1, 100)), cex = 1.0)
    })
  })

  # Validar pregunta te√≥rica
  observeEvent(input$validar_pregunta, {
    correcta <- input$pregunta_nodo == "prediccion"
    feedback <- if (correcta) {
      "¬°Correcto! Un nodo terminal representa la predicci√≥n final de clase."
    } else {
      "Incorrecto. Un nodo terminal contiene la predicci√≥n final de clase para un subconjunto de observaciones."
    }

    output$feedback_pregunta <- renderUI({
      div(class = if (correcta) "alert alert-success" else "alert alert-warning", feedback)
    })
  })

  # Validar interpretaci√≥n de gr√°fico de poda
  observeEvent(input$validar_grafico, {
    req(rv$tree_model)

    cv_results <- rpart::printcp(rv$tree_model)
    optimal_point <- which.min(cv_results[, "xerror"]) + 1

    # Verificar si menciona el punto √≥ptimo y explica por qu√©
    mencion_optimo <- grepl(as.character(optimal_point), input$interpretacion_grafico) ||
                     grepl("√≥ptimo|punto m√≠nimo|donde error deja", tolower(input$interpretacion_grafico))
    explica_razon <- grepl("error|disminuir|mejor|√≥ptimo", tolower(input$interpretacion_grafico))

    correcta <- mencion_optimo && explica_razon

    feedback <- if (correcta) {
      paste0("¬°Excelente interpretaci√≥n! El punto √≥ptimo est√° en ", optimal_point,
             " nodos donde el error de validaci√≥n cruzada es m√≠nimo.")
    } else {
      paste0("Revisa el gr√°fico. El punto √≥ptimo est√° donde el error deja de disminuir significativamente (alrededor de ",
             optimal_point, " nodos). Despu√©s de ese punto, agregar m√°s nodos no mejora el rendimiento.")
    }

    output$feedback_grafico <- renderUI({
      div(class = if (correcta) "alert alert-success" else "alert alert-info", feedback)
    })
  })

  # Validar interpretaci√≥n de nodo
  observeEvent(input$guardar_interpretacion, {
    req(rv$nodo_aleatorio)

    node <- rv$nodo_aleatorio
    clase <- c("bajo", "medio", "alto")[node$yval]

    # Interpretaci√≥n esperada b√°sica
    interpretacion_correcta <- grepl(tolower(clase), tolower(input$interpretacion_nodo)) &&
                              (grepl("predice|predicci√≥n|clasifica", tolower(input$interpretacion_nodo)) ||
                               grepl("riesgo", tolower(input$interpretacion_nodo)))

    feedback <- if (interpretacion_correcta) {
      paste0("¬°Buena interpretaci√≥n! El nodo predice riesgo ", clase,
             " para el ", node$n, "% de las observaciones que llegan a √©l.")
    } else {
      paste0("Revisa tu interpretaci√≥n. El nodo predice riesgo ", clase,
             ". Considera mencionar qu√© tipo de riesgo predice y qu√© porcentaje de observaciones representa.")
    }

    output$feedback_interpretacion <- renderUI({
      div(class = if (interpretacion_correcta) "alert alert-success" else "alert alert-info", feedback)
    })
  })

  # Mostrar informaci√≥n de nodo aleatorio
  output$info_nodo_aleatorio <- renderUI({
    req(rv$tree_model)

    if (is.null(rv$nodo_aleatorio)) {
      rv$nodo_aleatorio <- select_random_node(rv$tree_model)
    }

    if (is.null(rv$nodo_aleatorio)) return(NULL)

    node <- rv$nodo_aleatorio
    clase <- c("bajo", "medio", "alto")[node$yval]

    div(
      h5("Informaci√≥n del Nodo Seleccionado:"),
      p(strong("ID del Nodo:"), node$node_id),
      p(strong("Clase Predicha:"), clase),
      p(strong("N√∫mero de observaciones:"), node$n),
      p(strong("Regla:"), node$rule)
    )
    # -------------------------
    # Validaci√≥n y propagaci√≥n de semilla
    # -------------------------
    rv$semilla <- NULL
  
    observeEvent(input$validar_codigo, {
      codigo <- trimws(input$codigo_pucp)
      if (!grepl("^[0-9]{8}$", codigo)) {
        output$mensaje_codigo <- renderUI({
          div(class = "alert alert-danger", "El c√≥digo debe tener exactamente 8 d√≠gitos num√©ricos.")
        })
        shinyjs::hide(id = "main_panel")
        return()
      }
  
      rv$semilla <- as.numeric(codigo)
      set.seed(rv$semilla)
      output$mensaje_codigo <- renderUI({
        div(class = "alert alert-success", paste("Semilla configurada exitosamente con c√≥digo", codigo))
      })
  
      # Mostrar el panel principal y ocultar la entrada de c√≥digo
      shinyjs::show(id = "main_panel")
    })
  })

  # -------------------------
  # Tab 3: Poda del √Årbol
  # -------------------------

  # Curva de error vs tama√±o
  output$plot_error_vs_size <- renderPlot({
    req(rv$tree_model)

    cv_results <- rpart::printcp(rv$tree_model)
    plot(cv_results[, "nsplit"] + 1, cv_results[, "xerror"],
         type = "b", xlab = "Tama√±o del √Årbol (nodos terminales)",
         ylab = "Error de Validaci√≥n Cruzada", main = "Error vs Tama√±o del √Årbol")
    abline(v = which.min(cv_results[, "xerror"]) + 1, col = "red", lty = 2)
    text(which.min(cv_results[, "xerror"]) + 1, min(cv_results[, "xerror"]),
         "Tama√±o √ìptimo", pos = 4, col = "red")
  })


  # Informaci√≥n de poda
  output$info_poda <- renderUI({
    req(rv$tree_model)

    cv_results <- rpart::printcp(rv$tree_model)
    optimal_size <- which.min(cv_results[, "xerror"]) + 1
    current_size <- sum(rv$tree_model$frame$var == "<leaf>")

    div(
      p(strong("Tama√±o actual del √°rbol:"), current_size, "nodos terminales"),
      p(strong("Tama√±o √≥ptimo recomendado:"), optimal_size, "nodos terminales"),
      p("Aplicar poda reducir√° la complejidad del modelo y puede mejorar su capacidad de generalizaci√≥n.")
    )
  })

  # Aplicar poda autom√°tica con CP √≥ptimo
  observeEvent(input$aplicar_poda, {
    req(rv$tree_model)

    # Calcular poda autom√°tica con CP √≥ptimo por validaci√≥n cruzada
    poda_result <- prune_tree(rv$tree_model, rv$train_data)
    rv$pruned_model <- poda_result$pruned
    rv$poda_info <- poda_result

    rv$poda_aplicada <- TRUE

    quiet_notify("Poda aplicada exitosamente con CP √≥ptimo.", type = "message")
  })

  # Visualizaci√≥n √°rbol original
  output$plot_arbol_original <- renderPlot({
    req(rv$tree_model)
    tryCatch({
      rpart.plot::rpart.plot(rv$tree_model, main = "√Årbol Original",
                            extra = 104, box.palette = "RdYlGn", shadow.col = "gray", roundint = FALSE)
    }, error = function(e) {
      plot.new()
      text(0.5, 0.5, paste("Error al graficar √°rbol original:\n", substr(e$message, 1, 100)), cex = 1.0)
    })
  })

  # Visualizaci√≥n √°rbol podado
  output$plot_arbol_podado <- renderPlot({
    req(rv$pruned_model)
    tryCatch({
      rpart.plot::rpart.plot(rv$pruned_model, main = "√Årbol Podado",
                            extra = 104, box.palette = "RdYlGn", shadow.col = "gray", roundint = FALSE)
    }, error = function(e) {
      plot.new()
      text(0.5, 0.5, paste("Error al graficar √°rbol podado:\n", substr(e$message, 1, 100)), cex = 1.0)
    })
  })

  # Tabla comparaci√≥n
  output$tabla_comparacion_arboles <- DT::renderDT({
    req(rv$tree_model, rv$pruned_model)

    original_size <- sum(rv$tree_model$frame$var == "<leaf>")
    pruned_size <- sum(rv$pruned_model$frame$var == "<leaf>")

    # Calcular accuracy en test set
    if (!is.null(rv$test_data)) {
      nd_test <- .align_types_for_predict(rv$tree_model, rv$test_data)
      pred_original <- safe_predict_class(rv$tree_model, nd_test)
      pred_pruned <- safe_predict_class(rv$pruned_model, nd_test)

      acc_original <- mean(pred_original == rv$test_data$alerta_riesgo)
      acc_pruned <- mean(pred_pruned == rv$test_data$alerta_riesgo)
    } else {
      acc_original <- acc_pruned <- NA
    }

    df_comp <- data.frame(
      √Årbol = c("Original", "Podado"),
      "Nodos Terminales" = c(original_size, pruned_size),
      "Accuracy Test" = c(acc_original, acc_pruned),
      check.names = FALSE
    )

    DT::datatable(df_comp, options = list(dom = "t", paging = FALSE)) %>%
      DT::formatRound("Accuracy Test", 3)
  })

  # Validar reflexiones
  observeEvent(input$validar_reflexiones, {
    req(rv$tree_model, rv$pruned_model)

    original_size <- sum(rv$tree_model$frame$var == "<leaf>")
    pruned_size <- sum(rv$pruned_model$frame$var == "<leaf>")
    nodos_eliminados <- original_size - pruned_size

    rendimiento_similar <- abs(input$pregunta_rendimiento == "si")
    nodos_correctos <- abs(input$nodos_eliminados == nodos_eliminados)
    ventaja_mencionada <- grepl("simple|interpretable|generaliza", tolower(input$ventaja_podado))

    score <- sum(c(rendimiento_similar, nodos_correctos, ventaja_mencionada))

    feedback <- paste0("Puntuaci√≥n: ", score, "/3. ",
                      "Nodos eliminados: ", nodos_eliminados, ".")

    quiet_notify(feedback, type = "message")
  })

  # -------------------------
  # Tab 4: Matriz de Confusi√≥n y M√©tricas
  # -------------------------

  # Calcular m√©tricas cuando se cambia el modelo
  observe({
    req(rv$pruned_model, rv$test_data)

    pred <- safe_predict_class(rv$pruned_model, rv$test_data)
    rv$test_predictions <- pred
    rv$metrics <- calculate_metrics(pred, rv$test_data$alerta_riesgo, input$umbral_clasificacion)
  })

  # Matriz de confusi√≥n
  output$plot_matriz_confusion <- renderPlot({
    req(rv$metrics)

    conf_mat <- rv$metrics$confusion_matrix
    ggplot2::ggplot(as.data.frame(conf_mat), ggplot2::aes(x = Actual, y = Predicted, fill = Freq)) +
      ggplot2::geom_tile(color = "white") +
      ggplot2::geom_text(ggplot2::aes(label = Freq), vjust = 1) +
      ggplot2::scale_fill_gradient(low = "white", high = "steelblue") +
      ggplot2::labs(title = "Matriz de Confusi√≥n", x = "Real", y = "Predicho") +
      ggplot2::theme_minimal()
  })

  # Tabla matriz de confusi√≥n
  output$tabla_matriz_confusion <- DT::renderDT({
    req(rv$metrics)
    DT::datatable(as.data.frame(rv$metrics$confusion_matrix),
                  options = list(dom = "t", paging = FALSE))
  })

  # Mostrar m√©tricas actuales del modelo
  output$metricas_actuales <- renderUI({
    req(rv$metrics)

    div(
      h5("M√©tricas actuales del modelo:"),
      p(strong("Accuracy:"), round(rv$metrics$accuracy, 3)),
      p(strong("Sensibilidad:"), round(rv$metrics$macro_recall, 3)),
      p(strong("Especificidad:"), round(rv$metrics$macro_specificity, 3)),
      p(strong("F1-Score:"), round(rv$metrics$macro_f1, 3))
    )
  })

  # Validar respuesta m√©trica
  observeEvent(input$validar_metrica, {
    req(rv$metrics, input$metrica_interpretar)

    metrica_valor <- switch(input$metrica_interpretar,
                           "sensibilidad" = rv$metrics$macro_recall,
                           "especificidad" = rv$metrics$macro_specificity,
                           "accuracy" = rv$metrics$accuracy,
                           "f1" = rv$metrics$macro_f1)

    # Respuestas esperadas seg√∫n la m√©trica
    respuestas_esperadas <- list(
      "sensibilidad" = c("detecta casos positivos", "identifica alto riesgo", "casos de riesgo alto"),
      "especificidad" = c("detecta casos negativos", "identifica bajo riesgo", "casos de riesgo bajo"),
      "accuracy" = c("predicciones correctas", "total correctas", "porcentaje correctas"),
      "f1" = c("balance precisi√≥n sensibilidad", "media arm√≥nica", "precisi√≥n y sensibilidad")
    )

    respuesta_correcta <- any(sapply(respuestas_esperadas[[input$metrica_interpretar]],
                                    function(palabra) grepl(tolower(palabra), tolower(input$respuesta_metrica))))

    feedback <- if (respuesta_correcta) {
      paste0("¬°Buena interpretaci√≥n! El valor de ", round(metrica_valor, 3),
             " indica que el modelo tiene un buen rendimiento en esta m√©trica.")
    } else {
      paste0("Revisa tu interpretaci√≥n. Un valor de ", round(metrica_valor, 3),
             " para ", input$metrica_interpretar, " significa que el modelo...",
             switch(input$metrica_interpretar,
                   "sensibilidad" = "detecta correctamente esa proporci√≥n de casos de alto riesgo.",
                   "especificidad" = "identifica correctamente esa proporci√≥n de casos de bajo riesgo.",
                   "accuracy" = "realiza esa proporci√≥n de predicciones correctas en total.",
                   "f1" = "balancea precisi√≥n y sensibilidad con ese valor."))
    }

    output$feedback_metrica <- renderUI({
      div(class = if (respuesta_correcta) "alert alert-success" else "alert alert-info", feedback)
    })
  })

  # Pregunta Verdadero/Falso 1
  output$pregunta_vf_1 <- renderUI({
    preguntas_vf <- list(
      "Si aumenta el umbral de clasificaci√≥n, la sensibilidad del modelo aumenta." = FALSE,
      "Si aumenta el n√∫mero de Verdaderos Negativos (TN), la especificidad aumenta." = TRUE,
      "Un accuracy de 0.95 significa que el 95% de las predicciones son correctas." = TRUE,
      "La sensibilidad mide la capacidad de detectar casos positivos." = TRUE,
      "Si disminuye el umbral, aumenta la especificidad del modelo." = FALSE,
      "El F1-Score es √∫til cuando queremos balancear precisi√≥n y sensibilidad." = TRUE,
      "Un modelo con alta sensibilidad comete pocos Falsos Negativos." = TRUE,
      "La especificidad mide la capacidad de identificar casos negativos." = TRUE
    )

    pregunta <- sample(names(preguntas_vf), 1)
    rv$respuesta_vf_correcta_1 <- preguntas_vf[[pregunta]]

    div(
      h5("Pregunta 1 - Verdadero o Falso:"),
      p(pregunta)
    )
  })

  # Pregunta Verdadero/Falso 2
  output$pregunta_vf_2 <- renderUI({
    preguntas_vf <- list(
      "Si aumenta el umbral de clasificaci√≥n, disminuye la sensibilidad." = TRUE,
      "Un aumento en Falsos Positivos (FP) mejora la especificidad." = FALSE,
      "La precisi√≥n mide la calidad de las predicciones positivas." = TRUE,
      "Un modelo con alta especificidad comete pocos Falsos Positivos." = TRUE,
      "Si disminuye el umbral, aumenta el n√∫mero de Falsos Positivos." = TRUE,
      "El accuracy incluye tanto positivos como negativos correctamente clasificados." = TRUE,
      "La sensibilidad es igual al recall en problemas de clasificaci√≥n binaria." = TRUE,
      "Un F1-Score de 1.0 indica un modelo perfecto." = TRUE
    )

    pregunta <- sample(names(preguntas_vf), 1)
    rv$respuesta_vf_correcta_2 <- preguntas_vf[[pregunta]]

    div(
      h5("Pregunta 2 - Verdadero o Falso:"),
      p(pregunta)
    )
  })

  # Validar V/F
  observeEvent(input$validar_vf, {
    correcta_1 <- (input$respuesta_vf_1 == "verdadero") == rv$respuesta_vf_correcta_1
    correcta_2 <- (input$respuesta_vf_2 == "verdadero") == rv$respuesta_vf_correcta_2

    score <- sum(correcta_1, correcta_2)

    feedback <- paste0("Puntuaci√≥n: ", score, "/2. ",
                      if (correcta_1) "Pregunta 1 correcta. " else "Pregunta 1 incorrecta. ",
                      if (correcta_2) "Pregunta 2 correcta." else "Pregunta 2 incorrecta.")

    output$feedback_vf <- renderUI({
      div(class = if (score == 2) "alert alert-success" else
                  if (score == 1) "alert alert-warning" else "alert alert-danger",
          feedback)
    })
  })

  # -------------------------
  # Tab 5: Clasificaci√≥n de Alertas
  # -------------------------

  # Clasificar datos N3 (simulados como nuevos)
  observe({
    req(rv$pruned_model)

    # Usar un subset de datos hist√≥ricos como "N3" (nuevas observaciones)
    df_n3 <- rv$df_historico[sample(1:nrow(rv$df_historico), 100), ]

    rv$n3_predictions <- classify_new_data(rv$pruned_model, df_n3)
  })

  # Tabla de clasificaci√≥n
  output$tabla_clasificacion <- DT::renderDT({
    req(rv$n3_predictions)

    df_display <- rv$n3_predictions[, c("id_cliente", "clase_predicha", "prob_bajo", "prob_medio", "prob_alto", "nivel_alerta")]
    colnames(df_display) <- c("ID Cliente", "Clase Predicha", "Prob Baja", "Prob Media", "Prob Alta", "Nivel Alerta")

    DT::datatable(df_display, options = list(pageLength = 10)) %>%
      DT::formatRound(c("Prob Baja", "Prob Media", "Prob Alta"), 3)
  })

  # Gr√°fico de pie
  output$plot_pie_clasificacion <- renderPlot({
    req(rv$n3_predictions)

    dist_clases <- table(rv$n3_predictions$clase_predicha)
    pie(dist_clases,
        main = "Distribuci√≥n de Alertas de Riesgo",
        col = c("green", "yellow", "red"),
        labels = paste(names(dist_clases), "\n", dist_clases))
  })

  # -------------------------
  # Persistencia y finalizaci√≥n
  # -------------------------
  observeEvent(input$finalizar_modulo, {
    req(rv$pruned_model, rv$metrics, rv$n3_predictions)

    # Persistir evaluaci√≥n
    persist_eval_m4(
      id_sim = id_sim,
      accuracy = rv$metrics$accuracy,
      macro_f1 = rv$metrics$macro_f1,
      n_nodos = sum(rv$pruned_model$frame$var == "<leaf>"),
      vars_usadas = paste(input$vars_predictoras, collapse = ",")
    )

    # Persistir clasificaciones N3
    persist_clasificaciones_m4(
      id_sim = id_sim,
      clasificaciones = rv$n3_predictions
    )

    quiet_notify("M√≥dulo 4 completado y resultados guardados.", type = "message")
  })

}