# -1017.986
# c)
sigma11 = matrix(c(4),1,1)
sigma11 + sigma12%*%solve(sigma22)%*%t(sigma12)
# P(X1 > 5 | X2 = 9.8, X3= 5.5) = 1 - P(X1 <= 5 | X2 = 9.8, X3= 5.5)
1 - pnorm(5,3.928937,sqrt(4.285113))
A = matrix(c(0,1,-1),1,3)
mu = matrix(c(4,10,7),3,1)
A%*%mu
# V(X)
sigma = matrix(c(4,-2,0.03,-2,16,4,0.03,4,9),3,3)
A%*%sigma%*%t(A)
# P(Y > 0) = 1 - P(Y <= 0)
1 - pnorm(0,3,sqrt(17))
# Pregunta 8
datos = read.csv(file.choose())
colnames(datos)
modelo1 = lm(Y ~ X1 + X2 + X3, datos)
modelo1 = lm(Y ~ X1 + X2 + X3 + X4, datos)
modelo2 = lm(Y ~ X1 + X2 + X3, datos)
# a)
summary(modelo1)
# b)
predict(modelo1, newdata = data.frame(X1 = 5000,
X2= 3,
X3 = 30,
X4 = 300))
View(datos)
predict(modelo1, newdata = data.frame(X1 = 5,
X2= 3,
X3 = 30,
X4 = 300))
# c)
summary(modelo1)
# F-statistic: 54.41 on 4 and 995 DF,  p-value: < 2.2e-16
qf(0.95,4,995)
# e)
modelo1 = lm(Y ~ X1 + X2 + X3 + X4, datos)
modelo2 = lm(Y ~ X1 + X2 + X3, datos)
summary(modelo1)
summary(modelo2)
# f)
cor(datos$X3,datos$Y)
# g)
by(datos$Y, datos$X6, mean)
modelo9 = lm(y ~ X1 + X2 + X3 + X4 + factor(X5) + factor(X6),datos)
modelo9 = lm(Y ~ X1 + X2 + X3 + X4 + factor(X5) + factor(X6),datos)
# a)
summary(modelo9)
# b)
# Contraste de Adecuación del Modelo de Regresión Lineal
# Ho: B1 = B2 = B3 = B4 = B5 = B6 = B7 = 0
# Ha: Existe al menos un Bj diferente de cero.
# p-value: < 2.2e-16 < 0.05
# F-statistic: 151.7 on 7 and 992 DF
qf(0.95,7,992)
View(datos)
predict(modelo1, newdata = data.frame(X1 = 5.9,
X2= 2.5,
X3 = 38,
X4 = 550,
X5 = "Perro",
X6 = "Ocasional"))
predict(modelo9, newdata = data.frame(X1 = 5.9,
X2= 2.5,
X3 = 38,
X4 = 550,
X5 = "Perro",
X6 = "Ocasional"))
# e)
summary(modelo9)
# e)
plot(modelo9)
# (X1,X2,X3,X4)T ~ Multinomial(n = 100, p1 = 0.30, p2 = 0.27, p3 = 0.23, p4 = 0.20)
# X1 + X2 ~ Binomial (n = 100, p =  p1 + p2)
p1 = 0.30
p2 = 0.27
# P(X1 + X2 > 60) = 1 - P(X1 + X2 <= 60)
1 - pbinom(60,100,p1+p2)
p1 = 0.30
p2 = 0.27
p3 = 0.23
p4 = 0.20
# b)
# P(X1 | (X1 U X2 U X3)) = P(X1 n (X1 U X2 U X3))/P(X1 U X2 U X3)
# P(X1 | (X1 U X2 U X3)) = P(X1)/P(X1 U X2 U X3)
# P(X1 | (X1 U X2 U X3)) = p1/(p1+p2+p3)
p1/(p1+p2+p3)
# Y: Número de clientes que prefieren pagar con Tarjeta de Crédito
# si se sabe que 74 pagan con medios de pago distintos a efectivo
# Y ~ Binomial(n = 74, p = 0.375)
n = 74
p = 0.375
n*p
# c)
# C = 0.5X1 + 0.5X2 + 0.2X3 + 0.8X4
A = matrix(c(0.5,0.5,0.2,0.8),1,4)
# Y: Número de clientes que prefieren pagar con Tarjeta de Crédito
# si se sabe que 74 pagan con medios de pago distintos a efectivo
# Y ~ Binomial(n = 74, p = 0.375)
n = 74
py = 0.375
# Y: Número de clientes que prefieren pagar con Tarjeta de Crédito
# si se sabe que 74 pagan con medios de pago distintos a efectivo
# Y ~ Binomial(n = 74, p = 0.375)
ny = 74
py = 0.375
ny*py
n = 100
p = c(0.30,0.27,0.23,0.20)
A = matrix(c(0.5,0.5,0.2,0.8),1,4)
mu = matrix(n*p,4,1)
# E(C)
A%*%mu
sigma = -n*p%*%t(p)
sigma
diag(sigma) = n*p*(1-p)
sigma
# V(C)
A%*%sigma%*%t(A)
tabla= matrix(c(50,40,30,20,
60,45,35,25,
30,35,40,40),3,4,byrow=TRUE)
Edad<-c("18-30","31-50","50-mas")
Metodo<-c("TarjetaCredito","TarjetaDebito","Transeferencia","Efectivo")
dimnames(tabla)= list(Edad=Edad,Metodo=Metodo)
prop.table(tabla,1)
t <- prop.table(tabla, margin = 2)
round(t,3)
barplot(t,
main = "Distribución de Edad según Medio de Pago",
xlab = "Contenido Consumido",
ylab = "Proporción",
col = 1:4,
legend.text = rownames(t),
args.legend = list(x = "topleft", title = "Perfil Cliente",
cex=0.6, bty = "n"),
beside = TRUE,
ylim = c(0,1))
t <- prop.table(tabla, margin = 2)
round(t,3)
barplot(t,
main = "Distribución de Edad según Medio de Pago",
xlab = "Contenido Consumido",
ylab = "Proporción",
col = 1:3,
legend.text = rownames(t),
args.legend = list(x = "topleft", title = "Perfil Cliente",
cex=0.6, bty = "n"),
beside = TRUE,
ylim = c(0,1))
prop.table(tabla,2)
prop.table(tabla,2)
t <- prop.table(tabla, margin = 2)
round(t,3)
barplot(t,
main = "Distribución de Rango Etareo según Medio de Pago",
xlab = "Contenido Consumido",
ylab = "Proporción",
col = 1:3,
legend.text = rownames(t),
args.legend = list(x = "topleft", title = "Rango Etareo",
cex=0.6, bty = "n"),
beside = TRUE,
ylim = c(0,1))
# La distribución de rangos etareos para cada medio de pago no es
# la misma, por lo tanto se puede considerar que existe asociación
# entre estas dos variables
chisq.test(tabla)
# Tabla de Frecuencias Esperadas
chisq.test(tabla)$expected
# Valor Critico
qchisq(0.95,6)
# f)
tabla
# f)
sum(tabla)
sum(tabla)
addmargins(tabla)
p1 = 140/450
p2 = 120/450
n = 450
alfa = 0.05
IC <- function(p1,p2,n,alfa){
LI = p1 - p2 - qnorm(1 - alfa/2)*sqrt( (p1*(1-p1) + p2*(1-p2) + 2*p1*p2)/n )
LS = p1 - p2 + qnorm(1 - alfa/2)*sqrt( (p1*(1-p1) + p2*(1-p2) + 2*p1*p2)/n )
c(LI,LS)
}
IC
IC(p1,p2,n,alfa)
p1 = 50/140
p2 = 60/165
# Poblaciones Independientes
n1 = 140
n2 = 165
alfa = 0.05
IC_indep <- function(p1,p2,n1,n2,alfa){
LI = p1 - p2 - qnorm(1 - alfa/2)*sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)
LS = p1 - p2 + qnorm(1 - alfa/2)*sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)
c(LI,LS)
}
IC_indep(p1,p2,n1,n2,alfa)
probabilidades = c(0.30, 0.27, 0.23, 0.20)
x = c(140, 120, 105, 85)
chisq.test(x,probabilidades)
chisq.test(x = muestra, p = probabilidades)
muestra = c(140, 120, 105, 85)
probabilidades = c(0.30, 0.27, 0.23, 0.20)
chisq.test(x = muestra, p = probabilidades)
# Estadístico de Prueba
# X-squared = 0.50322
qchisq(0.95,3)
shiny::runApp('GitHub/data-mining-learning-project')
shiny::runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
###### Pregunta 1
# a.
# Modelo 1
1 - pweibull(5,1,2)
# Modelo 2
1 - pgamma(5,2,scale = 1)
# Modelo 3
1/6
# b.
# Modelo 1
qweibull(0.60,1,2)
# Modelo 2
qgamma(0.60,2,scale = 1)
load(file.choose())
hist(data,
prob = T,
xlab = "Tiempo de duración en miles de horas",
ylab = "Densidad",
main = "Funciones Densidad",
ylim = c(0,0.45))
curve(dweibull(x,1,2), col = "firebrick", lwd = 3, from = 0, to = 15, add = T)
curve(dgamma(x,2,scale = 1), col = "steelblue", lwd = 3, add = T, from = 0, to = 15)
modelo_3_densidad = function(y) 1/y^2
curve(modelo_3_densidad,col = "darkgreen", lwd = 3, add = T,from = 0, to = 15)
modelo_3_acumulada = function(y) y/(1+y)
fun = ecdf(data)
plot(fun, main = "Funciones Acumuladas")
curve(pweibull(x,1,2), col = "firebrick", lwd = 3, from = 0, to = 15, add = T)
curve(pgamma(x,2,scale = 1), col = "steelblue", lwd = 3, add = T, from = 0, to = 15)
curve(modelo_3_acumulada,col = "darkgreen", lwd = 3, add = T,from = 0, to = 15)
###### Pregunta 2
# a.
p = 1 - pweibull(3,2,3)
p
(1-p)^2 * p
(1-p)^9 * p
# d.
qbinom(0.5,10,p)
###### Pregunta 3
# a)
# b)
# c)
0.6*dpois(0,2.5) + 0.4*dpois(1.5)
###### Pregunta 3
# a)
# b)
# c)
0.6*dpois(0,2.5) + 0.4*dpois(0,1.5)
0.6*dpois(1,2.5) + 0.4*dpois(1,1.5)
0.6*dpois(2,2.5) + 0.4*dpois(2,1.5)
0.6*dpois(3,2.5) + 0.4*dpois(3,1.5)
0.6*ppois(0,2.5) + 0.4*ppois(0,1.5)
0.6*ppois(0,2.5) + 0.4*ppois(0,1.5)
0.6*ppois(1,2.5) + 0.4*ppois(1,1.5)
0.6*ppois(2,2.5) + 0.4*ppois(2,1.5)
0.6*ppois(3,2.5) + 0.4*ppois(3,1.5)
fp = function(x) 0.6*dpois(x,2.5) + 0.4*dpois(x,1.5)
fp(1)
fp(0)
fp(2)
fp(3)
fpa(0)
fpa = function(x) 0.6*ppois(x,2.5) + 0.4*ppois(x,1.5)
fpa(0)
fpa(0)
fpa(0)
fpa(0)
fpa(1)
fpa(2)
fpa(3)
0.6*qpois(0.6,2.5) + 0.4*qpois(0.6,1.5)
p_a1 = pnorm(6,8,1.5)
p_a2 = pnorm(10,8,1.5) - pnorm(6,8,1.5)
p_a3 = 1 - pnorm(10,8,1.5)
p_e = 0.90*p_a1 + 0.60*p_a2 + 0.20*p_a3
p_e
# b)
p_a1*0.90/p_e
function(x) (50-x^2)/164
x = c(0,1,2,3)
function(x) (50-x^2)/164
x = c(0,1,2,3)
f = function(x) (50-x^2)/164
f = function(x) (50-x^2)/164
x = c(0,1,2,3)
# Esperanza
sum(x*f(x))
# Esperanza
EX = sum(x*f(x))
EX
# Varianza
EX2 = sum((x^2)*f(x))
VX = EX2 - (EX)^2
# Desviación Estándar
sigma = sqrt(VX)
sigma
# b)
(f(1) + f(2))/(f(1) + f(2) + f(3))
# b)
integrate(function(x) x*(2.5*x^(2.5-1)),0,1)
integrate(function(x) x*(10*x^(10-1)),0,0.7142857)
integrate(function(x) 10*x^(10-1),0,0.7142857)
integrate(function(x) 10*x^(10-1),0,0.7142857)
# b)
# c)
integrate(function(x) 10*x^(10-1),0,0.5)
integrate(function(x) 2.5*x^(2.5-1),0,0.5)
(1-0.15)*0.0009765625 + 0.15*0.1767767
# d)
load(file.choose())
hist(duracion, prob = T)
# d)
curve(function(x) 10*x^(10-1), col = "red", lwd = 2)
# d)
curve(function(x) 10*x^(10-1), col = "red", lwd = 2)
# d)
f_no_cont = 10*x^(10-1)
f_cont = 2.5*x^(2.5-1)
curve(f_no_cont, col = "red", lwd = 2)
curve(f_no_cont, col = "blue", lwd = 2)
# d)
f_no_cont = function(x) 10*x^(10-1)
f_cont = function(x) 2.5*x^(2.5-1)
curve(f_no_cont, col = "red", lwd = 2)
curve(f_no_cont, col = "blue", lwd = 2)
curve(f_no_cont, col = "red", lwd = 2)
curve(f_no_cont, col = "blue", lwd = 2)
curve(f_no_cont, col = "red", lwd = 2, add = T)
curve(f_no_cont, col = "blue", lwd = 2, add = T)
curve(f_no_cont, col = "red", lwd = 2, add = T)
curve(f_cont, col = "blue", lwd = 2, add = T)
# Puntos en [0,1]
n  <- 60
x  <- seq(0, 1, length.out = n)
# Curva base: exponencial reescalada (0 en x=0, 10 en x=1)
# s controla qué tan "plana" es al inicio y qué tan abrupta al final
s  <- 8
mu <- 10 * (exp(s * (x - 1)) - exp(-s)) / (1 - exp(-s))
# Ruido (ligeramente heterocedástico para verse más natural)
y  <- mu + rnorm(n, mean = 0, sd = 0.10 + 0.05 * mu)
# No negativos y monótona no decreciente (opcional)
y  <- pmax(y, 0)
y  <- cummax(y)
y
data = y
save(data, file = "duracion1.RData")
hist(y)
hist(1/y)
# Puntos en [0,1]
n  <- 60
x  <- seq(0, 1, length.out = n)
# Curva base: exponencial reescalada (0 en x=0, 10 en x=1)
# s controla qué tan "plana" es al inicio y qué tan abrupta al final
s  <- 8
mu <- 10 * (exp(s * (x - 1)) - exp(-s)) / (1 - exp(-s))
# Ruido (ligeramente heterocedástico para verse más natural)
y  <- mu + rnorm(n, mean = 0, sd = 0.10 + 0.05 * mu)
data = y
save(data, file = "duracion1.RData")
hist(data)
data = x
save(data, file = "duracion1.RData")
hist(data)
hist(data, prob = T)
curve(f_no_cont, col = "red", lwd = 2, add = T)
curve(f_cont, col = "blue", lwd = 2, add = T)
hist(data, prob = T, ylim = c(0,100))
hist(data, prob = T, ylim = c(0,10))
set.seed(123)
n <- 2000
x <- rbeta(n, shape1 = 10, shape2 = 1)
data = x
hist(data, prob = T, ylim = c(0,10))
curve(f_no_cont, col = "red", lwd = 2, add = T)
curve(f_cont, col = "blue", lwd = 2, add = T)
f_no_cont = function(x) 10*x^(10-1)
f_cont = function(x) 2.5*x^(2.5-1)
hist(data, prob = T, ylim = c(0,10),
xlab = "Tiempos de duración",
ylab = "Densidad",
main = "Distribución de tiempos de duración")
curve(f_no_cont, col = "red", lwd = 2, add = T)
curve(f_cont, col = "blue", lwd = 2, add = T)
legend("topleft",
legend = c("Modelo 1, Modelo 2"),
col = c("red","blue"), lty = 1, lwd = 2, bty = "n")
legend("topleft",
legend = c("Modelo 1", "Modelo 2"),
col = c("red","blue"), lty = 1, lwd = 2, bty = "n")
hist(data, prob = T, ylim = c(0,10),
xlab = "Tiempos de duración",
ylab = "Densidad",
main = "Distribución de tiempos de duración")
curve(f_no_cont, col = "red", lwd = 2, add = T)
curve(f_cont, col = "blue", lwd = 2, add = T)
legend("topleft",
legend = c("Modelo 1", "Modelo 2"),
col = c("red","blue"), lty = 1, lwd = 2, bty = "n")
##### Pregunta 3
# a)
1 - pnorm(60,50,12)
##### Pregunta 3
# a)
p = 1 - pnorm(60,50,12)
pbinom(5,30,p)
# b)
qnorm(0.25,50,12)
qnorm(0.25,50,12)
qnorm(0.50,50,12)
qnorm(0.75,50,12)
# b)
load(file.choose())
quantile(llamadas1$x, 0.25)
quantile(llamadas1$x, 0.25)
quantile(llamadas1$x, 0.50)
quantile(llamadas1$x, 0.75)
View(llamadas1)
# Extra
50*pnorm(60,50,12) + 100*(1 - pnorm(60,50,12))
# 60.11642
500*60.11642
shiny::runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
shiny::runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
shiny::runApp('GitHub/data-mining-learning-project')
shiny::runApp('GitHub/data-mining-learning-project')
gamma(1+1/2)
qweibull(0.15,2,2.2568)
(pweibull(3,2,2.2568) - pweibull(2,2,2.2568))/(1 - pweibull(2,2,2.2568))
data = read.csv(file.choose())
View(data)
hist(data)
hist(data$ingreso_miles_soles)
hist(data$ingreso_miles_soles, prob = T)
data = read.csv(file.choose())
hist(data$ingreso_miles_soles, prob = T,
main = "Histograma de Ingreso Región A",
xlab = "Ingreso",
ylab = "Densidad")
curve(dweibull(x,2,2.2568), col = "red", lwd = 2, add = T)
plot(density(data$ingreso_miles_soles))
curve(dweibull(x,2,2.2568), col = "red", lwd = 2, add = T)
plot(density(data$ingreso_miles_soles),
main = "Curva de Densidad de Ingreso Región A",
xlab = "Ingreso",
ylab = "Densidad")
curve(dweibull(x,2,2.2568), col = "red", lwd = 2, add = T)
qexp(0.5,scale = 36)
qexp(0.5,1/36)
?pexp
(1 - pexp(4,1/36))/(1 - pexp(2,1/36))
(1 - pexp(4,1/36))/(1 - pexp(2,1/36))
data = read.csv(file.choose())
quantile(data$vida_meses,0.25)
qexp(0.25,1/36)
IQR(data$vida_meses)
qexp(0.75,1/36) - qexp(0.25,1/36)
1 - pnorm(60,50,12)
pbinom(5,30,0.2023)
load(file.choose())
data = read.csv(file.choose())
summary(data$tiempo_minutos)
qnorm(0.25,50,12)
qnorm(0.50,50,12)
qnorm(0.75,50,12)
1 - ppois(6,4.41)
ppois(7,4.41) - ppois(2,4.41)
qpois(0.90,4.41)
qpois(0.75,4.41) - qpois(0.25,4.41)
shiny::runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
shiny::runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
shiny::runApp('GitHub/data-mining-learning-project')
