View(mpg)
# a.
autos_manual = mpg[mpg$Transmission.Type == "MANUAL",]
View(autos_manual)
boxplot(autos_manual$Engine.HP, horizontal = T)
Q1 = quantile(autos_manual$Engine.HP,0.25)
Q3 = quantile(autos_manual$Engine.HP,0.75)
RIC = Q3 - Q1
LI = Q1 - 1.5*RIC
LS = Q3 + 1.5*RIC
autos_manual$Engine.HP < LI
sum(autos_manual$Engine.HP < LI)
autos_manual$Engine.HP > LS)
autos_manual$Engine.HP > LS
sum(autos_manual$Engine.HP > LS)
atipicos = sum(autos_manual$Engine.HP < LI) + sum(autos_manual$Engine.HP > LS)
total = length(autos_manual$Engine.HP)
porcentaje = (atipicos/total)*100
porcentaje
# b.
# Como dicen 25%
# Calculamos el Cuantil 25 / Cuartil 1
quantile(mpg$city.mpg,0.25)
boxplot(autos_manual$Engine.HP, horizontal = T)$out
outliers = boxplot(autos_manual$Engine.HP, horizontal = T)$out
length(outliers)
quantile(mpg$city.mpg,0.75)
# c.
autos_traccion_delantera = mpg[mpg$Driven_Wheels == "front wheel drive",]
hist(autos_traccion_delantera$Engine.HP)
density(autos_traccion_delantera$Engine.HP)
plot(density(autos_traccion_delantera$Engine.HP))
desvest = sd(autos_traccion_delantera$Engine.HP)
media = mean(autos_traccion_delantera$Engine.HP)
mediana = median(autos_traccion_delantera$Engine.HP)
desvest = sd(autos_traccion_delantera$Engine.HP)
3*(media - mediana)/desvest
# d.
autos_manual = mpg[mpg$Transmission.Type == "MANUAL",]
mean(autos_manual$Engine.HP)
autos_automatica = mpg[mpg$Transmission.Type == "AUTOMATIC",]
mean(autos_automatica$Engine.HP) # 241.599
by(mpg$Engine.HP,mpg$Transmission.Type,mean)
install.packages("DescTools")
library(DescTools)
install.packages("DescTools")
library(DescTools)
?DescTools
Skew(autos_traccion_delantera$Engine.HP)
??Skew
load(file.choose())
View(ENAHO2019_Ingreso_Norte)
shiny::runApp('GitHub/data-mining-learning-project/www')
data = read.csv(file.choose())
# 9.
# a.
MINSA = data[data$institucion == "MINSA",]
# Proporción de personas que tienen 40 años o menos
fun = ecdf(MINSA$edad)
fun(40)
# b.
MINSA = data[data$institucion == "ESSALUD",]
# b.
ESSALUD = data[data$institucion == "ESSALUD",]
# Proporción de personas que tienen 40 años o menos
# Usamos la función de distribución acumulada empírica
fun = ecdf(ESSALUD$edad)
1 - fun(50)
# c.
library(DescTools)
Skew(MINSA$edad)
# Asimetría según Pearson
3*(mean(MINSA$edad) - median(MINSA$edad))/sd(MINSA$edad)
# Asimetría según Pearson
3*(mean(MINSA$edad) - median(MINSA$edad))/sd(MINSA$edad)
# Asimetría
Pearson.asi = function(x) 3*(mean(x) − median(x))/sd(x)
Fisher.asi = function (x) mean((x − mean(x))^3)/sd(x)^3
# Asimetría
Pearson.asi = function(x) 3*(mean(x) − median(x))/sd(x)
# Asimetría
Pearson.asi = function(x) 3*(mean(x) − median(x))/sd(x)
3*(mean(x) − median(x))/sd(x)
# Asimetría
Pearson.asi = function(x) 3*(mean(x) − median(x))/sd(x)
# Asimetría
Pearson.asi = function(x) 3*(mean(x) - median(x))/sd(x)
Fisher.asi = function(x) mean((x − mean(x))^3)/sd(x)^3
Fisher.asi = function(x) mean((x - mean(x))^3)/sd(x)^3
Pearson.asi(MINSA$edad)
Fisher.asi(MINSA$edad)
Skew(MINSA$edad)
View(data)
Privadas = data[data$institucion == "Clinicas",]
Pearson.asi(Privadas$edad) # -0.002545067
Fisher.asi(Privadas$edad) # 0.06126328
Skew(Privadas$edad) # 0.06126328
# d.
boxplot(MINSA$edad, plot = F)
# d.
boxplot(MINSA$edad, plot = F)$out
# d.
boxplot(MINSA$edad, plot = F)$out
# Por definición
LI = quantile(MINSA$edad, 0.25)
LS = quantile(MINSA$edad, 0.75)
# Por definición
Q1 = quantile(MINSA$edad, 0.25)
Q3 = quantile(MINSA$edad, 0.75)
RIC = Q3 - Q1
LS = Q3 + 1.5*RIC
sum(data$edad < LI) + sum(data$edad > LS)
Q1 = quantile(MINSA$edad, 0.25)
Q3 = quantile(MINSA$edad, 0.75)
RIC = Q3 - Q1
LI = Q1 - 1.5*RIC
LS = Q3 + 1.5*RIC
sum(MINSA$edad < LI) + sum(MINSA$edad > LS)
?boxplot
LI = Q1 - 1.5*RIC
LS = Q3 + 1.5*RIC
# Por definición
Q1 = quantile(MINSA$edad, 0.25)
Q3 = quantile(MINSA$edad, 0.75)
load(file.choose())
View(ENL2022)
# a).
prop.table(table(ENL2022$P429_8_1))
# b).
EstratoBajo = ENL2022[ENL2022$P412_1 == 5,]
EstratoAlto = ENL2022[ENL2022$P412_1 == 1,]
View(EstratoAlto)
View(EstratoBajo)
EstratoBajo = ENL2022[ENL2022$ESTRATOSOCIO == 5,]
EstratoAlto = ENL2022[ENL2022$ESTRATOSOCIO == 1,]
View(EstratoBajo)
# Calculamos la media de la cantidad de libros P412_1
mean(EstratoBajo$P412_1)
mean(EstratoAlto$P412_1)
# c).
EstratoMedioBajo = ENL2022[ENL2022$ESTRATOSOCIO == 4]
# c).
EstratoMedioBajo = ENL2022[ENL2022$ESTRATOSOCIO == 4,]
quantile(EstratoMedioBajo$P418,0.75)
# c).
# Forma Teórica
Q1 = quantile(ENL2022$P418, 0.25)
Q3 = quantile(ENL2022$P418, 0.75)
RIC = Q3 - Q1
LI = Q1 - 1.5*RIC
LS = Q3 + 1.5*RIC
sum(ENL2022$P418 < LI) + sum(ENL2022$P418 > LS)
# Forma Práctica $out
boxplot(ENL2022$P418)
# Forma Práctica $out
boxplot(ENL2022$P418, plot = F)
# Forma Práctica $out
boxplot(ENL2022$P418, plot = F)$out
# Forma Práctica $out
length(boxplot(ENL2022$P418, plot = F)$out)
# c).
# Forma Teórica
Q1 = quantile(ENL2022$P418, 0.25)
Q1
LI
quantile(EstratoMedioBajo$P314,0.75)
# e).
hist(ENL2022$P314)
# Edad
hist(ENL2022$P210_A)
IQR(ENL2022$P314)
IQR(ENL2022$P210_A)
# % Porcentaje
311/4443
# % Porcentaje
(311/4443)*100
View(ENL2022)
# f).
Mujeres = ENL2022[ENL2022$P209 == 2,]
library(DescTools)
Skew(Mujeres$P314)
# Coef. Asimetría Pearson
3*(mean(Mujeres$P314) - median(Mujeres$P314))/sd(Mujeres$P314)
Hombres = ENL2022[ENL2022$P209 == 1,]
# Coef. Asimetría Fisher
library(DescTools)
Skew(Hombres$P314) # 4.009978 Asimetría Positiva
# Coef. Asimetría Pearson
3*(mean(Hombres$P314) - median(Hombres$P314))/sd(Mujeres$P314)
# Coef. Asimetría Pearson
3*(mean(Hombres$P314) - median(Hombres$P314))/sd(Hombres$P314)
# Pregunta 2.
# a.
modeloX = lm(P418 ~ P412_1, data = ENL2022)
summary(modeloX)
modeloZ = lm(P418 ~ P412_2, data = ENL2022)
summary(modeloZ)
# b.
modeloMultiple = lm(P418 ~ P412_1 + P412_2 + P429_8_1, data = ENL2022)
summary(modeloMultiple)
# b.
modeloMultiple = lm(P418 ~ P412_1 + P412_2 + factor(P429_8_1),
data = ENL2022)
summary(modeloMultiple)
197.535 + 21.486*(3) + 3.015*(2)
shiny::runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
library(shinyjs)
install.packages("shinyjs")
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
mu_X = matrix(c(28.5,
18.2,
12.8,
15,
10.5),
5,1)
mu_X
sigma = matrix(c(3,2.8,-2.2,-1.5,0.8,
2.8,5.2,-3.8,1.2,-0.5,
-2.2,-3.8,4.1,0.9,-1.3,
-1.5,1.2,0.9,2.7,0.4,
0.8,-0.5,-1.3,0.4,1.9
),
5,5)
sigma_X = matrix(c(3,2.8,-2.2,-1.5,0.8,
2.8,5.2,-3.8,1.2,-0.5,
-2.2,-3.8,4.1,0.9,-1.3,
-1.5,1.2,0.9,2.7,0.4,
0.8,-0.5,-1.3,0.4,1.9
),
5,5)
sigma_X
0.80*28.5
1.20*28.5
# P(22.8 < X < 34.2) = P(X < 34.2) - P(X < 22.8)
pnorm(34.2, 28.5, sqrt(3)) - pnorm(22.8, 28.5, sqrt(3))
# b.
mu_2 = 12.8
sigma_12 = matrix(c(-2.2,3.8),2,1)
sigma_12
sigma_11 = matrix(c(3,2.8,2.8,5.2),2,2)
sigma_11
x1 = matrix(c(32,20),2,1)
mu_1 = matrix(c(28.5, 18.2),2,1)
mu_2 + t(sigma_12)%*%solve(sigma_11)%*%(x1 - mu_1)
# c.
A = matrix(c(9.8,6.5,3.1,4.2,5.6),1,5)
# c.
A = matrix(c(9.8,6.5,3.1,4.2,5.6),1,5)
mu_X = matrix(c(28.5,18.2,12.8,15,10.5),5,1)
A%*%mu_X
A%*%sigma_X%*%t(A)
# d.
# P(250 < C < 300)
pnorm(300,559.08,sqrt(714.905)) - pnorm(250,559.08,sqrt(714.905))
# Pregunta 3)
# a.
# P(X1 <= 8.8)
# X1 ~ N(mu = 7.5, sigma^2 = 1.2)
pnorm(8.8,7.5,sqrt(1.2))
# Correlaciones
corX1X4 = covX1X4/sqrt(sigma2X1*sigma2X4)
sigma2X1 = 1.2
sigma2X2 = 1
sigma2X3 = 0.5
sigma2X4 = 5
# Covarianzas
covX1X4 = 0
covX2X4 = 1.1
covX3X4 = -1
# Correlaciones
corX1X4 = covX1X4/sqrt(sigma2X1*sigma2X4)
corX2X4 = covX2X4/sqrt(sigma2X2*sigma2X4)
corX3X4 = covX3X4/sqrt(sigma2X3*sigma2X4)
corX1X4
corX2X4
corX3X4
A = matrix(c(0,1,1,0),1,4)
mu_X = matrix(c(7.5,2.25,1.5,50),1,4)
mu_C = A%*%mu_X
A = matrix(c(0,1,1,0),1,4)
mu_X = matrix(c(7.5,2.25,1.5,50),1,4)
mu_C = A%*%mu_X
mu_X = matrix(c(7.5,2.25,1.5,50),4,1)
mu_C = A%*%mu_X
A = matrix(c(0,1,1,0),1,4)
mu_X = matrix(c(7.5,2.25,1.5,50),4,1)
mu_C = A%*%mu_X
mu_C = A%*%mu_X
mu_C
sigma_X = matrix(c(1.2,0.4,0.1,0,
0.4,1,0.2,1.1,
0.1,0.2,0.5,-1,
0,1.1,-1,5),4,4)
A%*%sigma_X%*%t(A)
1 - pnorm(3.75,sqrt(1.9))
# P(X2 + X3 > 4) = 1 - P(X2 + X3 <= 4)
# X2 + X3 ~ N(mu = 3.75, sigma^2 = 1.9)
1 - pnorm(4, 3.75,sqrt(1.9))
# P(X2 + X3 > 4) = 1 - P(X2 + X3 <= 4)
# X2 + X3 ~ N(mu = 3.75, sigma^2 = 1.9)
1 - pnorm(4,3.75,sqrt(1.9))
# d.
mu_2 = matrix(c(50),1,1)
sigma_12 = matrix(c(1.1),1,1)
sigma_11 = matrix(c(1),1,1)
x1 = matrix(c(2),1,1)
mu_1 = matrix(c(2.25),1,1)
mu_2 + t(sigma_12)%*%solve(sigma_11)%*%(x1-mu_1)
mu_1 = matrix(c(7.5,2.25,1.5),3,1)
sigma_12 = matrix(c(0,1.1,-1),3,1)
mu_1 = matrix(c(7.5,2.25,1.5),3,1)
sigma_12 = matrix(c(0,1.1,-1),3,1)
sigma_22 = matrix(c(5),1,1)
mu_1 + sigma_12%*%solve(sigma_22)%*%(x2-mu_2)
mu_1 = matrix(c(7.5,2.25,1.5),3,1)
sigma_12 = matrix(c(0,1.1,-1),3,1)
sigma_22 = matrix(c(5),1,1)
x2 = 50
mu_2 = 50
mu_1 + sigma_12%*%solve(sigma_22)%*%(x2-mu_2)
mu_X1 = mu_1 + sigma_12%*%solve(sigma_22)%*%(x2-mu_2)
sigma_11 = matrix(c(1.2,0.4,0.1,0.4,1,0.2,0.1,0.2,0.5),3,3)
sigma_11 - sigma_12%*%solve(sigma_22)%*%t(sigma_12)
sigma_X1 = sigma_11 - sigma_12%*%solve(sigma_22)%*%t(sigma_12)
# U = X1 - X2 - X3
A = matrix(c(1,-1,-1),1,3)
A%*%mu_X1
# Varianza U
A%*%sigma_X1%*%t(A)
# P(U > 0) = 1 - pnorm(U < 0)
1 - pnorm(0,3.75, sqrt(2.098))
# b.
?dmultinom
dmultinom(c(36,20,16,8),80,c(0.45,0.25,0.20,0.10))
# c.
# Xv ~ Binomial(n = 150, p = 0.25)
# P(Xv <= 40) # A lo más 40
pbinom(40,150,0.25)
# Xc ~ Binomial(n = 150, p = 0.45)
# E(Xc)
EXc = 150*0.45
# Xv ~ Binomial(n = 150, p = 0.25)
EXv = 150*0.25
# Xh ~ Binomial(n = 150, p = 0.20)
EXh = 150*0.20
# Xe ~ Binomial(n = 150, p = 0.10)
EXe = 150*0.10
# E(fee) = 25E(Xc) + 30E(Xv) + 40E(Xh) + 20E(Xe)
25*EXc + 30*EXv + 40*EXh + 20*EXe
mu_X = matrix(c(EXc,EXv,EXh,EXe),4,1)
A = matrix(c(25,30,40,20),1,4)
mu_X = matrix(c(EXc,EXv,EXh,EXe),4,1)
A%*%mu_X
p_X = matrix(c(0.45, 0.25, 0.20, 0.10),4,1)
n = 150
p_X = matrix(c(0.45, 0.25, 0.20, 0.10),4,1)
n*p_x
p_X = matrix(c(0.45, 0.25, 0.20, 0.10),4,1)
n*p_x
p_x = matrix(c(0.45, 0.25, 0.20, 0.10),4,1)
n*p_x
mu_X = n*p_x
A%*%mu_X
p_x = matrix(c(0.09, 0.2475, 0.1125, 0.05,
0.1375, 0.0625, 0.04, 0.11,
0.05, 0.02,0.055, 0.025),4,1)
p_x = matrix(c(0.09, 0.2475, 0.1125, 0.05,
0.1375, 0.0625, 0.04, 0.11,
0.05, 0.02,0.055, 0.025),12,1)
n = 300
p_y = matrix(c(0.09, 0.2475, 0.1125, 0.05,
0.1375, 0.0625, 0.04, 0.11,
0.05, 0.02,0.055, 0.025),12,1)
EY = n*p_y
EY
# f.
# Yv,a ~ Binomial(n = 300, pv,a = 0.1375)
# E(Yv,a)
300*0.1375
p_x = matrix(c(0.45, 0.25, 0.20, 0.10),4,1)
n = 300
mu_X = n*p_x
mu_X
sigma2_1 = n*p1*(1-p1)
n = 300
p1 = 0.45
p2 = 0.25
p3 = 0.20
p4 = 0.10
sigma2_1 = n*p1*(1-p1)
sigma2_2 = n*p2*(1-p2)
sigma2_3 = n*p3*(1-p3)
sigma2_4 = n*p4*(1-p4)
covX1X2 = -n*p1*p2
covX1X3 = -n*p1*p3
covX1X4 = -n*p1*p4
covX2X1 = covX1X2
covX2X3 = -n*p2*p3
covX2X4 = -n*p2*p4
covX3X1 = covX1X3
covX3X2 = covX2X3
covX3X4 = -n*p3*p4
covX4X1 = covX1X4
covX4X2 = covX2X4
covX4X3 = covX3X4
sigma = matrix(c(sigma2_1,covX1X2,covX1X3,covX1X4,
covX2X1,sigma2_2,covX2X3,covX2X4,
covX3X1,covX3X2,sigma2_3,covX3X4,
covX4X1,covX4X2,covX4X3,sigma2_4),
4,4)
sigma
# c.
# P(Xc = 135, Xv = 75, Xh = 60, Xe = 30)
dmultinom(c(135,75,60,30),300,c(0.45,0.25,0.20,0.10))
# d.
# X2 ~ Binomial(n = 300, p2 = 0.25)
# E(X2) = np2 =
300*0.25
# e.
# P(X2 <= 70)
pbinom(70, 300,0.25)
A = matrix(c(200,250,400,150),1,4)
p_x = matrix(c(0.45, 0.25, 0.20, 0.10),4,1)
n = 300
mu_X = n*p_x
A%*%mu_X
A = matrix(c(80,100,150,60),1,4)
p_x = matrix(c(0.45, 0.25, 0.20, 0.10),4,1)
n = 300
mu_X = n*p_x
A%*%mu_X
# V(Utilidad)
A%*%sigma%*%t(A)
# Desviación Estándar
sqrt(249300)
shiny::runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
runApp('GitHub/data-mining-learning-project')
## -----------------------------
## Simulación del TLC en R base
## -----------------------------
set.seed(123)           # Reproducibilidad
# Parámetros
n    <- 30              # tamaño de muestra por repetición
reps <- 10000           # número de repeticiones
lambda <- 1             # parámetro de la Exponencial (tasa)
# Población NO normal: Exponencial(λ)
# Generamos medias muestrales: Xbar_i = mean(X_i1, ..., X_in)
xbar <- replicate(reps, mean(rexp(n, rate = lambda)))
# Parámetros teóricos de la media muestral bajo TLC
mu_pop    <- 1 / lambda          # media poblacional de Exp(λ)
sd_pop    <- 1 / lambda          # desvío poblacional de Exp(λ)
sd_xbar   <- sd_pop / sqrt(n)    # desvío de la media muestral
# Histograma + ajuste normal teórico + densidad empírica
hist(xbar,
breaks = "FD",
freq   = FALSE,             # escala de densidad
col    = "lightgray",
border = "white",
main   = sprintf("TLC con Exponencial(λ=%g): medias de tamaño n=%d (reps=%d)", lambda, n, reps),
xlab   = "Media muestral")
# Densidad empírica (kernel)
lines(density(xbar), lwd = 2, lty = 2)
# Curva Normal teórica ~ N(mu_pop, sd_xbar^2)
curve(dnorm(x, mean = mu_pop, sd = sd_xbar),
add = TRUE, lwd = 2)
# Marcas en el eje
rug(xbar, col = "gray40")
# Leyenda
legend("topright",
legend = c("Densidad empírica", "Ajuste Normal teórico"),
lty    = c(2, 1),
lwd    = 2,
bty    = "n")
# (Opcional) Chequeo rápido numérico
c(
media_empirica   = mean(xbar),
media_teorica    = mu_pop,
sd_empirica      = sd(xbar),
sd_teorica       = sd_xbar
)
shiny::runApp('GitHub/data-mining-learning-project')
